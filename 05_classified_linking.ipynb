{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636a96be",
   "metadata": {},
   "source": [
    "# Linking Interaction-Level and Time-Resolved AIS Data\n",
    "\n",
    "## Purpose of this Notebook\n",
    "\n",
    "This notebook establishes a reliable link between time-resolved AIS observations\n",
    "and interaction-level behavioral summaries.\n",
    "\n",
    "The behavioral analysis performed in previous steps produces one row per\n",
    "ship–ship interaction (`behavior_summary.csv`), while the original AIS-based\n",
    "dataset (`classified_ais_dcpa_tcpa.csv`) contains one row per timestamp.\n",
    "To enable detailed inspection, visualization, and validation of ship behavior\n",
    "over time, it is necessary to connect these two representations.\n",
    "\n",
    "This notebook augments the time-resolved AIS dataset with interaction identifiers,\n",
    "resulting in a linked dataset (`classified_linked.csv`) where each AIS observation\n",
    "is assigned to a specific ship–ship interaction.\n",
    "\n",
    "This linkage enables:\n",
    "- Reconstruction of full interaction trajectories\n",
    "- Validation of behavioral summary metrics\n",
    "- Visualization of ship behavior over time\n",
    "- Consistent referencing between interaction-level and point-level data\n",
    "\n",
    "---\n",
    "\n",
    "## Input Data\n",
    "\n",
    "### 1. `classified_ais_dcpa_tcpa.csv`\n",
    "\n",
    "This dataset contains time-aligned AIS observations for pairs of ships.\n",
    "Each row represents a single timestamp and includes:\n",
    "\n",
    "- MMSI identifiers of both ships\n",
    "- Position (latitude, longitude)\n",
    "- Speed over ground and course over ground\n",
    "- Distance between ships\n",
    "- Risk indicators (DCPA and TCPA)\n",
    "- Region classification (harbor / open sea)\n",
    "\n",
    "### 2. `behavior_summary.csv`\n",
    "\n",
    "This dataset contains one row per ship–ship interaction and summarizes\n",
    "the behavioral response of both vessels during the interaction.\n",
    "Each interaction is identified by:\n",
    "- A canonical ship pair\n",
    "- An interaction identifier\n",
    "- Temporal bounds (start and end time)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concept: Canonical Ship Pairs\n",
    "\n",
    "AIS data may represent the same ship pair in different orders\n",
    "(e.g., ship A as `mmsi_1` and ship B as `mmsi_2`, or vice versa).\n",
    "\n",
    "To ensure consistent interaction assignment, ship pairs are transformed into\n",
    "a canonical representation:\n",
    "\n",
    "- `ship_low`  = minimum of the two MMSI values\n",
    "- `ship_high` = maximum of the two MMSI values\n",
    "\n",
    "This guarantees that `(A, B)` and `(B, A)` are treated as the same ship pair\n",
    "throughout the interaction definition and linking process.\n",
    "\n",
    "---\n",
    "\n",
    "## Interaction Assignment Strategy\n",
    "\n",
    "Interactions are defined by grouping AIS observations for the same canonical\n",
    "ship pair and splitting them when the time gap between consecutive observations\n",
    "exceeds a specified threshold (60 minutes).\n",
    "\n",
    "Each AIS observation is assigned:\n",
    "- `ship_low`\n",
    "- `ship_high`\n",
    "- `interaction_id`\n",
    "\n",
    "These identifiers exactly match those used in `behavior_summary.csv`,\n",
    "ensuring a one-to-many relationship between interactions and AIS observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad4928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classified: (677044, 17)\n",
      "✅ Saved linked classified file: classified_ais_dcpa_tcpa_linked.csv\n",
      "Columns added: ship_low, ship_high, interaction_id\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Add interaction linking columns to classified_ais_dcpa_tcpa.csv\n",
    "# Produces: classified_ais_dcpa_tcpa_linked.csv\n",
    "# (Adds ship_low, ship_high, interaction_id to every AIS pair row)\n",
    "# + Includes simple verification tests against behavior_summary.csv\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "CLASSIFIED_FILE = \"classified_ais_dcpa_tcpa.csv\"\n",
    "BEHAVIOR_FILE   = \"behavior_summary.csv\"   \n",
    "OUTPUT_FILE     = \"classified_ais_dcpa_tcpa_linked.csv\"\n",
    "\n",
    "MAX_TIME_GAP_SEC = 3600  # must match the behavior notebook\n",
    "\n",
    "# ----------------------------\n",
    "# Load\n",
    "# ----------------------------\n",
    "df = pd.read_csv(CLASSIFIED_FILE, parse_dates=[\"time_window\"])\n",
    "print(\"Loaded classified:\", df.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Canonical pair (A,B) == (B,A)\n",
    "# ----------------------------\n",
    "df[\"ship_low\"]  = df[[\"mmsi_1\", \"mmsi_2\"]].min(axis=1)\n",
    "df[\"ship_high\"] = df[[\"mmsi_1\", \"mmsi_2\"]].max(axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Sort by canonical pair + time\n",
    "# ----------------------------\n",
    "df = df.sort_values([\"ship_low\", \"ship_high\", \"time_window\"]).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Define interactions (same logic as behavior notebook)\n",
    "# ----------------------------\n",
    "df[\"time_diff_s\"] = (\n",
    "    df.groupby([\"ship_low\", \"ship_high\"])[\"time_window\"]\n",
    "      .diff()\n",
    "      .dt.total_seconds()\n",
    ")\n",
    "\n",
    "df[\"new_interaction\"] = df[\"time_diff_s\"].isna() | (df[\"time_diff_s\"] > MAX_TIME_GAP_SEC)\n",
    "\n",
    "df[\"interaction_id\"] = (\n",
    "    df.groupby([\"ship_low\", \"ship_high\"])[\"new_interaction\"]\n",
    "      .cumsum()\n",
    "      .astype(int) - 1\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Save linked classified file\n",
    "# ----------------------------\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✅ Saved linked classified file: {OUTPUT_FILE}\")\n",
    "print(\"Columns added: ship_low, ship_high, interaction_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ddccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 1: Sanity checks ---\n",
      "Any missing ship_low/ship_high? False False\n",
      "Any missing interaction_id? False\n",
      "interaction_id min/max: 0 153\n",
      "\n",
      "--- Test 2: Extract one interaction trajectory using behavior_summary.csv ---\n",
      "Loaded behavior_summary: (26946, 24)\n",
      "\n",
      "Selected interaction from behavior_summary:\n",
      "ship_low=227314000, ship_high=228238700, interaction_id=0\n",
      "start_time=2015-12-09 18:33:00, end_time=2015-12-10 03:09:00, points_count=357\n",
      "\n",
      "Trajectory extracted from linked classified CSV:\n",
      "traj rows: 758\n",
      "               time_window     mmsi_1     mmsi_2      lat_1     lon_1  \\\n",
      "134989 2015-12-09 18:33:00  228238700  227314000  48.292885 -5.090133   \n",
      "134990 2015-12-09 18:33:00  228238700  227314000  48.292885 -5.090133   \n",
      "134991 2015-12-09 18:38:00  228238700  227314000  48.292046 -5.088555   \n",
      "134992 2015-12-09 18:38:00  228238700  227314000  48.292046 -5.088555   \n",
      "134993 2015-12-09 18:43:00  227314000  228238700  48.288815 -5.088119   \n",
      "134994 2015-12-09 18:43:00  227314000  228238700  48.288815 -5.088119   \n",
      "134995 2015-12-09 18:48:00  227314000  228238700  48.290320 -5.085227   \n",
      "134996 2015-12-09 18:48:00  227314000  228238700  48.290320 -5.085227   \n",
      "134998 2015-12-09 18:53:00  227314000  228238700  48.289085 -5.084577   \n",
      "134997 2015-12-09 18:53:00  227314000  228238700  48.289085 -5.084577   \n",
      "\n",
      "        speed_1  course_1      lat_2     lon_2  speed_2  course_2  distance_m  \\\n",
      "134989      1.6     122.7  48.292973 -5.090915      1.6      69.1   58.845188   \n",
      "134990      1.6     122.7  48.292973 -5.090915      1.6      69.1   58.845188   \n",
      "134991      1.4     111.9  48.292835 -5.087863      1.7     336.2  101.640472   \n",
      "134992      1.4     111.9  48.292835 -5.087863      1.7     336.2  101.640472   \n",
      "134993      8.7     134.1  48.291410 -5.086797      1.4      75.9  304.768600   \n",
      "134994      8.7     134.1  48.291410 -5.086797      1.4      75.9  304.768600   \n",
      "134995      1.1     143.5  48.290573 -5.085020      1.3     156.1   32.035135   \n",
      "134996      1.1     143.5  48.290573 -5.085020      1.3     156.1   32.035135   \n",
      "134998      5.8     161.8  48.289692 -5.083173      2.1     158.1  124.095721   \n",
      "134997      5.8     161.8  48.289692 -5.083173      2.1     158.1  124.095721   \n",
      "\n",
      "            DCPA_m      TCPA_s   ship_low  ship_high  interaction_id  \n",
      "134989   58.729020    0.000000  227314000  228238700               0  \n",
      "134990   58.729020    0.000000  227314000  228238700               0  \n",
      "134991  101.145594    0.000000  227314000  228238700               0  \n",
      "134992  101.145594    0.000000  227314000  228238700               0  \n",
      "134993  303.098377    0.000000  227314000  228238700               0  \n",
      "134994  303.098377    0.000000  227314000  228238700               0  \n",
      "134995    3.287966  186.779766  227314000  228238700               0  \n",
      "134996    3.287966  186.779766  227314000  228238700               0  \n",
      "134998  123.716617    0.000000  227314000  228238700               0  \n",
      "134997  123.716617    0.000000  227314000  228238700               0  \n",
      "\n",
      "--- Test 3: Linking correctness checks ---\n",
      "Behavior start/end: 2015-12-09 18:33:00 2015-12-10 03:09:00\n",
      "Classified traj start/end: 2015-12-09 18:33:00 2015-12-10 03:09:00\n",
      "Time window match: ✅\n",
      "Key uniqueness inside trajectory: ✅\n",
      "Max time gap inside extracted interaction (s): 2340.0\n",
      "Gap rule satisfied: ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TESTS / VERIFICATION\n",
    "# ============================================================\n",
    "\n",
    "# ---- Test 1: Basic sanity checks\n",
    "print(\"\\n--- Test 1: Sanity checks ---\")\n",
    "print(\"Any missing ship_low/ship_high?\", df[\"ship_low\"].isna().any(), df[\"ship_high\"].isna().any())\n",
    "print(\"Any missing interaction_id?\", df[\"interaction_id\"].isna().any())\n",
    "print(\"interaction_id min/max:\", df[\"interaction_id\"].min(), df[\"interaction_id\"].max())\n",
    "\n",
    "# ---- Test 2: Pull one interaction from behavior_summary and extract its full trajectory\n",
    "print(\"\\n--- Test 2: Extract one interaction trajectory using behavior_summary.csv ---\")\n",
    "try:\n",
    "    bs = pd.read_csv(BEHAVIOR_FILE, parse_dates=[\"start_time\", \"end_time\"])\n",
    "    print(\"Loaded behavior_summary:\", bs.shape)\n",
    "\n",
    "    # pick a \"good\" interaction: has multiple points and non-zero duration\n",
    "    candidate = bs.sort_values([\"points_count\", \"duration_min\"], ascending=False).iloc[0]\n",
    "\n",
    "    ship_low  = candidate[\"ship_low\"]\n",
    "    ship_high = candidate[\"ship_high\"]\n",
    "    inter_id  = candidate[\"interaction_id\"]\n",
    "    start_t   = candidate[\"start_time\"]\n",
    "    end_t     = candidate[\"end_time\"]\n",
    "\n",
    "    print(\"\\nSelected interaction from behavior_summary:\")\n",
    "    print(f\"ship_low={ship_low}, ship_high={ship_high}, interaction_id={inter_id}\")\n",
    "    print(f\"start_time={start_t}, end_time={end_t}, points_count={candidate['points_count']}\")\n",
    "\n",
    "    traj = df[\n",
    "        (df[\"ship_low\"] == ship_low) &\n",
    "        (df[\"ship_high\"] == ship_high) &\n",
    "        (df[\"interaction_id\"] == inter_id)\n",
    "    ].sort_values(\"time_window\")\n",
    "\n",
    "    print(\"\\nTrajectory extracted from linked classified CSV:\")\n",
    "    print(\"traj rows:\", len(traj))\n",
    "    print(traj[[\n",
    "        \"time_window\",\n",
    "        \"mmsi_1\", \"mmsi_2\",\n",
    "        \"lat_1\", \"lon_1\", \"speed_1\", \"course_1\",\n",
    "        \"lat_2\", \"lon_2\", \"speed_2\", \"course_2\",\n",
    "        \"distance_m\", \"DCPA_m\", \"TCPA_s\",\n",
    "        \"ship_low\", \"ship_high\", \"interaction_id\"\n",
    "    ]].head(10))\n",
    "\n",
    "    # ---- Test 3: Strong correctness test\n",
    "    # Check that the extracted trajectory time window matches behavior_summary\n",
    "    print(\"\\n--- Test 3: Linking correctness checks ---\")\n",
    "    if len(traj) == 0:\n",
    "        print(\"❌ ERROR: No rows found in classified for the selected behavior_summary interaction.\")\n",
    "    else:\n",
    "        traj_start = traj[\"time_window\"].iloc[0]\n",
    "        traj_end   = traj[\"time_window\"].iloc[-1]\n",
    "\n",
    "        print(\"Behavior start/end:\", start_t, end_t)\n",
    "        print(\"Classified traj start/end:\", traj_start, traj_end)\n",
    "\n",
    "        # Exact match should hold if both were computed with the same logic\n",
    "        ok_time_match = (traj_start == start_t) and (traj_end == end_t)\n",
    "        print(\"Time window match:\", \"✅\" if ok_time_match else \"⚠️ (check if behavior_summary was generated from same exact file)\")\n",
    "\n",
    "        # Check: all rows in this extracted traj have the same key (ship_low, ship_high, interaction_id)\n",
    "        ok_keys = (\n",
    "            (traj[\"ship_low\"].nunique() == 1) and\n",
    "            (traj[\"ship_high\"].nunique() == 1) and\n",
    "            (traj[\"interaction_id\"].nunique() == 1)\n",
    "        )\n",
    "        print(\"Key uniqueness inside trajectory:\", \"✅\" if ok_keys else \"❌\")\n",
    "\n",
    "        # Check: time gaps inside the interaction never exceed MAX_TIME_GAP_SEC (definition of interaction)\n",
    "        gaps = traj[\"time_window\"].diff().dt.total_seconds()\n",
    "        max_gap = gaps.max()\n",
    "        print(\"Max time gap inside extracted interaction (s):\", max_gap)\n",
    "        ok_gap = (pd.isna(max_gap) or max_gap <= MAX_TIME_GAP_SEC)\n",
    "        print(\"Gap rule satisfied:\", \"✅\" if ok_gap else \"❌\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ Could not find {BEHAVIOR_FILE}.\")\n",
    "    print(\"You can still use the linked classified file; tests 2/3 require behavior_summary.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eca9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deduplication: 677044\n",
      "Rows after deduplication:  516954\n",
      "Removed duplicates:        160090\n",
      "✅ Saved final linked file: classified_linked.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# Remove symmetric duplicate AIS pair rows\n",
    "# ----------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_in  = \"classified_ais_dcpa_tcpa_linked.csv\"\n",
    "file_out = \"classified_linked.csv\"\n",
    "\n",
    "df = pd.read_csv(file_in, parse_dates=[\"time_window\"])\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "# Drop duplicated observations caused by (A,B) vs (B,A)\n",
    "df = df.drop_duplicates(\n",
    "    subset=[\"time_window\", \"ship_low\", \"ship_high\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "after = len(df)\n",
    "\n",
    "df.to_csv(file_out, index=False)\n",
    "\n",
    "print(f\"Rows before deduplication: {before}\")\n",
    "print(f\"Rows after deduplication:  {after}\")\n",
    "print(f\"Removed duplicates:        {before - after}\")\n",
    "print(\"✅ Saved final linked file:\", file_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013574ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classified_linked: (516954, 22)\n",
      "Loaded behavior_summary: (26946, 24)\n",
      "\n",
      "Selected interaction:\n",
      "ship_low=212373000, ship_high=227297000, interaction_id=0\n",
      "Expected points_count: 4\n",
      "Start: 2015-11-17 19:11:00, End: 2015-11-17 19:14:00\n",
      "\n",
      "Extracted trajectory rows: 4\n",
      "\n",
      "Trajectory preview (first 10 rows):\n",
      "             time_window     mmsi_1     mmsi_2      lat_1     lon_1  speed_1  \\\n",
      "2774 2015-11-17 19:11:00  227297000  212373000  48.296932 -4.747700      5.1   \n",
      "2775 2015-11-17 19:12:00  227297000  212373000  48.296780 -4.749918      5.2   \n",
      "2776 2015-11-17 19:13:00  212373000  227297000  48.286070 -4.742983     12.7   \n",
      "2777 2015-11-17 19:14:00  212373000  227297000  48.287495 -4.738005     12.7   \n",
      "\n",
      "      course_1      lat_2     lon_2  speed_2  course_2   distance_m  \\\n",
      "2774     262.9  48.283173 -4.752725     12.0      64.0  1574.730481   \n",
      "2775     264.2  48.284615 -4.747889     12.9      65.9  1361.059796   \n",
      "2776      65.5  48.296326 -4.752366      5.4     253.7  1336.177500   \n",
      "2777      71.5  48.295887 -4.754612      5.7     254.3  1545.721821   \n",
      "\n",
      "           DCPA_m      TCPA_s   ship_low  ship_high  interaction_id  \n",
      "2774  1295.912828  101.047351  212373000  227297000               0  \n",
      "2775  1321.073736   31.758639  212373000  227297000               0  \n",
      "2776  1329.761714    0.000000  212373000  227297000               0  \n",
      "2777  1540.571495    0.000000  212373000  227297000               0  \n",
      "\n",
      "--- Final consistency checks ---\n",
      "Points count match: ✅\n",
      "Unique time_window: ✅\n",
      "Start time match: ✅\n",
      "End time match: ✅\n",
      "Max gap (s): 60.00000000000001\n",
      "Gap rule satisfied: ✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Load final datasets\n",
    "# ============================\n",
    "classified = pd.read_csv(\"classified_linked.csv\", parse_dates=[\"time_window\"])\n",
    "behavior = pd.read_csv(\"behavior_summary.csv\", parse_dates=[\"start_time\", \"end_time\"])\n",
    "\n",
    "print(\"Loaded classified_linked:\", classified.shape)\n",
    "print(\"Loaded behavior_summary:\", behavior.shape)\n",
    "\n",
    "# ============================\n",
    "# Select one interaction from behavior_summary\n",
    "# ============================\n",
    "row = behavior.sample(1, random_state=42).iloc[0]\n",
    "\n",
    "ship_low = row[\"ship_low\"]\n",
    "ship_high = row[\"ship_high\"]\n",
    "interaction_id = row[\"interaction_id\"]\n",
    "expected_points = row[\"points_count\"]\n",
    "\n",
    "print(\"\\nSelected interaction:\")\n",
    "print(f\"ship_low={ship_low}, ship_high={ship_high}, interaction_id={interaction_id}\")\n",
    "print(f\"Expected points_count: {expected_points}\")\n",
    "print(f\"Start: {row['start_time']}, End: {row['end_time']}\")\n",
    "\n",
    "# ============================\n",
    "# Extract trajectory\n",
    "# ============================\n",
    "traj = classified[\n",
    "    (classified[\"ship_low\"] == ship_low) &\n",
    "    (classified[\"ship_high\"] == ship_high) &\n",
    "    (classified[\"interaction_id\"] == interaction_id)\n",
    "].sort_values(\"time_window\")\n",
    "\n",
    "print(\"\\nExtracted trajectory rows:\", len(traj))\n",
    "\n",
    "# ============================\n",
    "# NEW: Show trajectory preview\n",
    "# ============================\n",
    "print(\"\\nTrajectory preview (first 10 rows):\")\n",
    "cols_to_show = [\n",
    "    \"time_window\",\n",
    "    \"mmsi_1\", \"mmsi_2\",\n",
    "    \"lat_1\", \"lon_1\", \"speed_1\", \"course_1\",\n",
    "    \"lat_2\", \"lon_2\", \"speed_2\", \"course_2\",\n",
    "    \"distance_m\", \"DCPA_m\", \"TCPA_s\",\n",
    "    \"ship_low\", \"ship_high\", \"interaction_id\"\n",
    "]\n",
    "cols_to_show = [c for c in cols_to_show if c in traj.columns]  # safe if a column is missing\n",
    "print(traj[cols_to_show].head(10))\n",
    "\n",
    "# ============================\n",
    "# Tests\n",
    "# ============================\n",
    "print(\"\\n--- Final consistency checks ---\")\n",
    "\n",
    "# 1. Row count match\n",
    "print(\"Points count match:\",\n",
    "      \"✅\" if len(traj) == expected_points else \"❌\")\n",
    "\n",
    "# 2. Unique timestamps\n",
    "print(\"Unique time_window:\",\n",
    "      \"✅\" if traj[\"time_window\"].is_unique else \"❌\")\n",
    "\n",
    "# 3. Time bounds match\n",
    "print(\"Start time match:\",\n",
    "      \"✅\" if traj[\"time_window\"].iloc[0] == row[\"start_time\"] else \"❌\")\n",
    "\n",
    "print(\"End time match:\",\n",
    "      \"✅\" if traj[\"time_window\"].iloc[-1] == row[\"end_time\"] else \"❌\")\n",
    "\n",
    "# 4. Max time gap rule\n",
    "max_gap = traj[\"time_window\"].diff().dt.total_seconds().max()\n",
    "print(\"Max gap (s):\", max_gap)\n",
    "print(\"Gap rule satisfied:\",\n",
    "      \"✅\" if max_gap <= 3600 else \"❌\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147977e",
   "metadata": {},
   "source": [
    "# Validation, Linking, and Deduplication\n",
    "\n",
    "## Interaction Linking Validation\n",
    "\n",
    "After assigning canonical ship pairs (`ship_low`, `ship_high`) and\n",
    "`interaction_id` values to the time-resolved AIS data, a series of validation\n",
    "steps are performed to ensure correctness and consistency between datasets.\n",
    "\n",
    "### 1. Completeness Check  \n",
    "All AIS observations are verified to contain valid values for:\n",
    "- `ship_low`\n",
    "- `ship_high`\n",
    "- `interaction_id`\n",
    "\n",
    "This confirms that every AIS row is assigned to a well-defined interaction.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Cross-Dataset Consistency Check  \n",
    "\n",
    "A random interaction is selected from `behavior_summary.csv`, and the\n",
    "corresponding full AIS trajectory is extracted from the linked classified data.\n",
    "\n",
    "The following conditions are verified:\n",
    "\n",
    "- The number of AIS rows matches `points_count`\n",
    "- The first and last timestamps match `start_time` and `end_time`\n",
    "- All timestamps within the interaction are unique\n",
    "- The maximum time gap within the trajectory respects the interaction\n",
    "  definition threshold (≤ 60 minutes)\n",
    "\n",
    "This step confirms that:\n",
    "- Interaction summaries are correctly linked to their underlying AIS data\n",
    "- Behavioral metrics were computed over the correct temporal windows\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Trajectory Reconstruction Verification  \n",
    "\n",
    "The extracted AIS trajectory is explicitly printed and inspected to confirm:\n",
    "\n",
    "- Correct temporal ordering\n",
    "- Consistent ship identity across rows\n",
    "- Physically meaningful evolution of position, speed, course, DCPA, and TCPA\n",
    "\n",
    "This provides a transparent, human-interpretable validation that each\n",
    "interaction corresponds to a coherent navigational situation.\n",
    "\n",
    "---\n",
    "\n",
    "## Duplicate Observation Handling\n",
    "\n",
    "During earlier preprocessing, ship pairs were treated as ordered\n",
    "(`(mmsi_1, mmsi_2)` and `(mmsi_2, mmsi_1)`), resulting in duplicated AIS rows\n",
    "that represent the same physical encounter.\n",
    "\n",
    "After introducing canonical ship pairing (`ship_low`, `ship_high`), these\n",
    "duplicates become identifiable.\n",
    "\n",
    "Duplicates are removed using the following keys:\n",
    "- `time_window`\n",
    "- `ship_low`\n",
    "- `ship_high`\n",
    "- `interaction_id`\n",
    "\n",
    "This deduplication step ensures that:\n",
    "- Each AIS observation appears exactly once\n",
    "- Interaction trajectories are not artificially inflated\n",
    "- Behavioral metrics and visualizations are not biased by duplicated data\n",
    "\n",
    "The effectiveness of deduplication is verified by re-running the trajectory\n",
    "extraction and confirming that row counts now exactly match\n",
    "`points_count` from `behavior_summary.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "## Output Data\n",
    "\n",
    "### `classified_linked.csv`\n",
    "\n",
    "The final output of this notebook is a **clean, deduplicated, and interaction-linked**\n",
    "AIS dataset containing:\n",
    "\n",
    "- Original time-resolved AIS measurements\n",
    "- Canonical ship pair identifiers (`ship_low`, `ship_high`)\n",
    "- Interaction identifiers (`interaction_id`)\n",
    "\n",
    "This dataset serves as the foundation for:\n",
    "- Detailed trajectory visualization\n",
    "- Interaction-level case studies\n",
    "- Behavioral pattern analysis\n",
    "- Validation of interaction summaries\n",
    "- Subsequent modeling or classification work\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation Note\n",
    "\n",
    "This notebook establishes a **reliable one-to-one link** between:\n",
    "- Interaction-level behavioral summaries  \n",
    "- Time-resolved AIS trajectories  \n",
    "\n",
    "Together, `behavior_summary.csv` and `classified_linked.csv` form the final,\n",
    "consistent data representation used for all subsequent behavioral analysis\n",
    "and visualization stages of the thesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d6516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
